# ğŸš€ EnterpriseRAG-AI

**EnterpriseRAG-AI** is a **multi-tenant Retrieval Augmented Generation (RAG) platform**
built for **enterprise knowledge systems**.

It enables organizations to securely upload documents, store embeddings,
and query them using LLM-powered RAG â€” with **tenant/workspace isolation**.

ğŸŒ Live Demo: https://enterpriserag-ai.vercel.app  
âš™ï¸ Backend API: https://enterpriserag-production.up.railway.app

---

## âœ¨ Key Features

- ğŸ” JWT-based Authentication (Signup / Login)
- ğŸ¢ Multi-tenant / Workspace architecture
- ğŸ“„ Document upload & ingestion
- ğŸ§  Vector search using FAISS
- ğŸ¤– LLM-powered RAG querying
- âš¡ FastAPI backend
- ğŸ¨ React + Vite frontend
- â˜ï¸ Deployed on Railway & Vercel

---

## ğŸ§± Tech Stack

### Backend
- **FastAPI**
- **SQLAlchemy**
- **PostgreSQL**
- **JWT (python-jose)**
- **Passlib (bcrypt)**
- **Sentence Transformers**
- **FAISS**

### Frontend
- **React (Vite)**
- **TypeScript**
- **Axios**
- **Context API**

---

## ğŸ“‚ Project Structure

```text
EnterpriseRAG-AI/
â”œâ”€â”€ app/                  # FastAPI backend
â”‚   â”œâ”€â”€ api/              # API routes
â”‚   â”œâ”€â”€ core/             # Security, config
â”‚   â”œâ”€â”€ db/               # DB session & init
â”‚   â”œâ”€â”€ models/           # SQLAlchemy models
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ frontend/             # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ rag/
â”‚
â”œâ”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ” Authentication Flow
Signup
{
  "email": "user@company.com",
  "password": "test123",
  "tenant_id": "tenant1",
  "role": "user"
}

Login

Returns a JWT access token used for protected APIs.

ğŸ§  How RAG Works 

Documents are uploaded and chunked

Embeddings are generated using Sentence Transformers

Vectors are stored in FAISS

User query â†’ vector search

Relevant context injected into LLM

LLM generates final answer

ğŸ§ª Local Development
Backend
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload


Backend runs on:

http://localhost:8000

Frontend
cd frontend
npm install
npm run dev


Frontend runs on:

http://localhost:5173

ğŸŒ Deployment

Backend â†’ Railway

Frontend â†’ Vercel

CORS configured for both local and production environments.

ğŸ›¡ï¸ Security Notes

Passwords hashed with bcrypt (72-byte safe limit)

JWT tokens include expiry (exp)

Tenant ID required to enforce isolation

Protected routes via dependency injection

ğŸ‘¨â€ğŸ’» Author

Devesh Chauhan
AI / Backend Engineer

GitHub: https://github.com/devloperdevesh
